version: '3.8'

services:
  web:
    build: .
    ports:
      - "8000:8000"
    environment:
      - MODEL_API_URL=${MODEL_API_URL}
      - MODEL_NAME=${MODEL_NAME}
      - REDIS_HOST=redis
    depends_on:
      - redis
      - ollama
      - model-pull
  ui:
    image: node:18
    working_dir: /app
    command: sh -c "npm install && npm run dev -- --host 0.0.0.0 --port 5173"
    ports:
      - "5173:5173"
    environment:
      - VITE_DEV_PROXY_TARGET=http://web:8000
      - VITE_DEV_SERVER_OPEN=false
    volumes:
      - ./ui:/app
    depends_on:
      - web
  agent:
    build: .
    command: ["python3", "-m", "app.agency_loop"]
    depends_on:
      - web
      - redis
    environment:
      - REDIS_HOST=redis
  redis:
    image: redis:7
    ports:
      - "6379:6379"

  ollama:
    image: ollama/ollama
    restart: always
    ports:
      - "${OLLAMA_PORT}:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=${OLLAMA_HOST}
    healthcheck:
      test: curl -f http://localhost:11434 || exit 1
      interval: 10s
      timeout: 20s
      retries: 5

  model-pull:
    image: curlimages/curl:8.8.0
    depends_on:
      - ollama
    entrypoint:
      - sh
      - -c
      - >
        set -e;
        until curl -fsS http://ollama:11434/api/version > /dev/null; do
          sleep 1;
        done;
        echo "Pulling model ${MODEL_NAME:-llama3} from Ollama...";
        curl -fsS -H 'Content-Type: application/json' \
          -d "{\"name\":\"${MODEL_NAME:-llama3}\"}" \
          http://ollama:11434/api/pull;
        echo "Model pulled."
    restart: "no"

volumes:
  ollama_data:
